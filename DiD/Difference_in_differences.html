<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Difference-in-Differences</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Dr. Christoph Hanck" />
    <script src="Difference_in_differences_files/header-attrs/header-attrs.js"></script>
    <link href="Difference_in_differences_files/remark-css/default.css" rel="stylesheet" />
    <script src="Difference_in_differences_files/xaringanExtra-progressBar/progress-bar.js"></script>
    <script src="Difference_in_differences_files/clipboard/clipboard.min.js"></script>
    <link href="Difference_in_differences_files/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="Difference_in_differences_files/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #00ff00\"><\/i>","error":"<i class=\"fa fa-times-circle\" style=\"color: #F94144\"><\/i>"})</script>
    <link href="Difference_in_differences_files/font-awesome/css/all.css" rel="stylesheet" />
    <link href="Difference_in_differences_files/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
    </script>
    <style>
    .mjx-mrow a {
      color: black;
      pointer-events: none;
      cursor: default;
    }
    </style>
    <link rel="stylesheet" href="../assets/ude_fonts.css" type="text/css" />
    <link rel="stylesheet" href="../assets/ude.css" type="text/css" />
    <link rel="stylesheet" href="../assetes/custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Difference-in-Differences
]
.author[
### Prof. Dr. Christoph Hanck
]
.date[
### Sommer 2023
]

---






<style>.xe__progress-bar__container {
  bottom:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 0.25em;
  background-color: #004c93;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>







#Across Within Variation
.vcenter[
- There are plenty of examples of treatments that occur at a particular time.
- It is of particular interest, how much of the change in the world is due to that treatment. 
- The goal is to identify a causal effect by comparing a group that received treatment before they received the treatment to after.
- Within variation is focused here.
- A back door that has to be dealed with can be summed up as **time.**
]
---
#Across Within Variation
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="Difference_in_differences_files/figure-html/unnamed-chunk-3-1.png" alt="1: Causal Diagram" width="55%" style="display:block; margin-right:auto; margin-left:auto;" /&gt;
&lt;p class="caption"&gt;1: Causal Diagram&lt;/p&gt;
&lt;/div&gt;
- Identifying the effect of `\(Treatment\)` on `\(Outcome\)` requires to close the back door that goes through `\(Time\)` .
- However, this cannot be done entirely, as all the variation in `\(Treatment\)` is explained by `\(Time\)` .

---
#Across Within Variation
.vcenter[
- Event studies solves this problem by trying to use before-treatment information to construct a counterfactual after-treatment untreated prediction. 
- Difference-in-differences (DID) takes a different approach.
 - It brings in another group that is never treated. 
 - Now in the data, both the group that receives treatment at a certain point, and another group that never receives treatment. 
]
---

#Across Within Variation
.vcenter[
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="Difference_in_differences_files/figure-html/unnamed-chunk-4-1.png" alt="2: Causal Diagram" width="55%" style="display:block; margin-right:auto; margin-left:auto;" /&gt;
&lt;p class="caption"&gt;2: Causal Diagram&lt;/p&gt;
&lt;/div&gt;


]
---
#Across Within Variation
.vcenter[
- The key is:
 - By introducing the control group, even though a new back door has been added, both back doors can be closed.
]

---
#Across Within Variation
.vcenter[
- This can be can be done by:
 - Isolate the within variation for both the treated group and untreated group. Because within variation has been isolated, group differences has been controlled for and back door has been closed through `\(Group\)` (the "differences")
 - Compare the within variation in the treated group to the within variation in the untreated group. Because the within variation in the untreated group is affected by time, doing this comparison controls for time differences and closes the back door through `\(Time\)` (the “difference” in those differences)
]

---
#Difference-in-Differences
.vcenter[
.blockquote[
###Example: Extent of the deviation is the effect of treatment.
- John Snow wanted to show the world that Cholera spreads by dirty drinking water. 
- He had a few ways of providing evidence, one of which is very similar to a modern-day difference-in-differences research design, and can be easily discussed in those terms (Coleman 2019).
- Snow’s “before” and “after” periods were 1849 and 1854, respectively. 
]]


---
#Difference-in-Differences
.vcenter[
.blockquote[
###Example: Extent of the deviation is the effect of treatment.
- London's drinking water supply was sourced from Thames river.
- Water taken in from the parts of the Thames that were downstream of London contained everything that Londoners dumped in the river, including plenty of fecal matter from people infected with cholera. 
- Between those two periods of 1849 and 1854, a policy was enacted - the Lambeth Company was required by an Act of Parliament to move their water intake upstream of London.
]]


---
#Difference-in-Differences
.vcenter[
.blockquote[
###Example: Effect of lambeth on cholera
- Lambeth moving their intake source gives  the **Treated group:** anyone in an area where the water came from the Lambeth company, and an **Untreated group:** anyone in an area without Lambeth.
- Then the question is: 
 - Did areas getting water from Lambeth see their Cholera numbers go down from 1849 to 1854 relative to areas getting no water from Lambeth?
]]


---
#Difference-in-Differences
.vcenter[
.blockquote[
###Example: Effect of lambeth on cholera
| Region Supplier       | Death rates (1849)    | Death rates (1854)  |
| :------------- |:-------------:| -----:|
| Non-Lambeth Only (Dirty)	     | 134.9	| 146.6 |
| Lambeth + Others (Mix Dirty and Clean)     | 130.1      |   84.9 |

&lt;br&gt;
- Death rates are deaths per 10,000 1851 population.
- It can be seen that from 1849 to 1854, the cholera problem in non-Lambeth areas got worse, rising from 135 to 147, while the problem in the Lambeth areas got better, dropping from 130 to 84.9.

]]



---
#Difference-in-Differences
.vcenter[
.blockquote[
###Example: Effect of lambeth on cholera
- The specific DID estimate we can get here is the Lambeth difference minus the non-Lambeth difference, or
`$$(84.9-130)-(147-135)=-57.1$$`
- The movement of the Lambeth pump reduced cholera mortality rates by 57.1 per 10,000 people.
]]


---
#Mechanics of DID
.vcenter[
.blockquote[
###Example: Effect of active choice on organ doner
- In US, everyone is assumed not to be an organ donor. People who are interested in donating organ opt in to the organ donation program when signing up for a driver's license.
- Outside of the opt-in and opt-out varieties of organ donation, there is also **active choice.** Under active choice, when one sign up for a driver’s license, one is asked to choose whether or not to be a donor.
- In July 2011, the state of California switched from opt-in to active choice.
]]




---
#Mechanics of DID
.vcenter[
.blockquote[
###Example: Effect of active choice on organ doner
- Kessler and Roth decided to compare California against the twenty-five states that either have opt-in or a verbally given question with no fixed response (difference). 
- Specifically, they compared the states on the basis of how their organ donation rates changed from before July 2011 to after (in differences).
]]

---
#Untreated Groups and Parallel Trends
.vcenter[
- For difference-in-differences approach to work, the **Unaffected group** also known as **Untreated group** is required.
- Features important to be present in untreated group:
 - Untreated group must satisfies the parallel trends assumption with the treated group.
]

---
#Untreated Groups and Parallel Trends
&lt;br&gt;&lt;br&gt;
**Parallel trends assumption**

&lt;br&gt;
- The parallel trends assumption says that, if no treatment had occurred, the difference between the treated group and the untreated group would have stayed the same in the post-treatment period as it was in the pre-treatment period.
- Parallel trends is inherently unobservable. It’s about the counterfactual of what would have happened if treatment had not occurred.

---
#Untreated Groups and Parallel Trends
&lt;br&gt;&lt;br&gt;
**Note**

&lt;br&gt;
- The entire plan behind a difference-in-differences design is to use the change in the untreated group to represent all non-treatment changes in the treated group.
- That way, once the untreated group’s change out is subtracted, only the treated group’s change is left. 
- Parallel trends is necessary to assume that works. If, without a treatment, the gap between the two groups would have changed from the pre-period to the post-period for any reason, or for no reason at all, then that non-treatment-related change will get mixed up with the treatment-related change, and cannot be told apart.

---
#Untreated Groups and Parallel Trends
&lt;br&gt;&lt;br&gt;
**In Mathematical terms**

&lt;br&gt;
- The difference between pre-treatment and post-treatment in the treated group is
`$$EffectOfTreatment+OtherTreatedGroupChanges$$`
- The difference between pre-treatment and post-treatment in the untreated group is `\(OtherUntreatedGroupChanges\)`

- Difference-in-difference subtracts one from the other, giving us `$$EffectOfTreatment+OtherTreatedGroupChanges-OtherUntreatedGroupChanges$$`

---
#Untreated Groups and Parallel Trends
&lt;br&gt;&lt;br&gt;
**How to pick an untreated comparison group is a parallel trend is required?**

&lt;br&gt;

- An untreated group must change by the same amount as the treated group (if treatment had occurred) from before the treatment is applied to afterwards.
- This means that there are a few good signs that can be looked for:
 - The untreated group would never suddenly change around the time of treatment.
 - The treated group and untreated groups are generally similar in many ways.
 - The treated group and untreated groups had similar trajectories for the dependent variable before treatment.
---
#Untreated Groups and Parallel Trends
&lt;br&gt;&lt;br&gt;
**How to check if the untreated group is appropriate?**

&lt;br&gt;

There are a few common ways to evaluate the parallel trends assumption:
- **Testing of prior trends**
 - This test looks to see whether the treated and untreated groups were trending similarly before treatment.


---
#Untreated Groups and Parallel Trends
&lt;br&gt;
**How to check if the untreated group is appropriate?**
.blockquote[
###Example:Prior Trends Test Looks Good for DID, and It Doesn’t
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="Difference_in_differences_files/figure-html/unnamed-chunk-5-1.png" alt="3: A Graph Where the Prior Trends Test Looks Good for DID, and a Graph Where It Does not " width="55%" style="display:block; margin-right:auto; margin-left:auto;" /&gt;
&lt;p class="caption"&gt;3: A Graph Where the Prior Trends Test Looks Good for DID, and a Graph Where It Does not &lt;/p&gt;
&lt;/div&gt;


]


---
#Untreated Groups and Parallel Trends
&lt;br&gt;
**How to check if the untreated group is appropriate?**

&lt;br&gt;
.blockquote[
###Example:Prior Trends Test Looks Good for DID, and It Doesn’t
- On the left, the distance between the treated and untreated group stays roughly constant in the leadup to treatment, even though both are trending upwards. 
 - This implies that, had the treatment not occurred, they likely would have continued having similar trends, lending more credibility to the parallel trends assumption. 

]
---
#Untreated Groups and Parallel Trends
&lt;br&gt;
**How to check if the untreated group is appropriate?**

&lt;br&gt;
.blockquote[
###Example:Prior Trends Test Looks Good for DID, and It Doesn’t
- On the right, the fairly large gap between the two has already shrunk by the time treatment goes into effect, with the untreated group starting lower but gaining on the treated group.
- That trend likely would have continued without treatment, and so parallel trends is unlikely to hold.
]

---
#Untreated Groups and Parallel Trends
&lt;br&gt;
**How to check if the untreated group is appropriate?**

- The second test that can ne perform is the placebo test. In a placebo test for difference-in-differences, a situation is taken where a treatment was applied in.
 - For example, March 2019. Then, the data only from before 2019 is used, ignoring all the data from the periods where treatment was actually applied.
- Then, using the pre-March 2019 data,  a few different periods are picked and pretended that the treatment was applied at that time. DID is estimated using that pretended treatment date. If a DID “effect” is found consistently at those pretended treatment dates, that gives a clue that something may be awry about the parallel trends assumption.

---
#Untreated Groups and Parallel Trends
&lt;br&gt;
**Note**

&lt;br&gt;
- Parallel trends means to think very carefully about how the dependent variable is measured and transformed. 
-  Because parallel trends is not just an assumption about causality, it is an assumption about the size of a gap remaining constant, which means something different depending on how you measure that gap.

---
#Untreated Groups and Parallel Trends
&lt;br&gt;
**Note**

&lt;br&gt;
- The most common way this pops up is when thinking about a dependent variable with a logarithm transformation. If parallel trends holds for dependent variable `\(Y\)` , then it does not hold for `\(ln(Y)\)` and vice versa - if it holds for `\(ln(Y)\)` it does not hold for `\(Y\)` .
- For example, say that in the pre-treatment period `\(Y\)` is 10 for the control group and 20 for the treated group. In the post-treatment period, in the counterfactual world where treatment never happened, `\(Y\)` would be 15 for the control group and 25 for the treated group. Gap of `\(20-10 = 10\)` before, and `\(25-15=10\)` after. Parallel trends holds.
---
#How Is It Performed?
&lt;br&gt;
**Two-Way Fixed Effects**
&lt;br&gt;
- The goal here is to control for group differences, and also control for time differences. 
- The regression is :
`$$Y = \alpha_g+\alpha_t+\beta_1Treated+\epsilon$$`
 - here `\(\alpha_g\)` is a set of fixed effects for the group - in the simplest form, just “Treated” or “Untreated” 

 - `\(\alpha_t\)` is a set of fixed effects for the time period  just “before treatment” and “after treatment.”
 - `\(Treated\)` then, is a binary variable indicating that one is being treated right now.
 - The coefficient on `\(Treated\)` is your difference-in-differences effect.
 
---
#How Is It Performed?
&lt;br&gt;
**Two-Way Fixed Effects**
&lt;br&gt;
- Control variables that change over time can be incorporated. 
- It can be thought that parallel trends only holds conditional on some variables - perhaps the untreated group dropped relative to treatment because some predictor `\(W\)` unrelated to treatment just happened to drop at the same time treatment went into effect, but `\(W\)` can control for.



---
#How Is It Performed?
&lt;br&gt;
**Two-Way Fixed Effects**
&lt;br&gt;

- Another way to write the same difference-in-difference equation if only two groups and two time periods is present is.
`$$Y = \beta_0+\beta_1TreatedGroup+\beta_2AfterTreatment+\beta_3TreatedGroup\times AfterTreatment+\epsilon$$`
 - where `\(TreatedGroup\)` is an indicator of the group being treated
 - `\(AfterTreatment\)` is an indicator of the “post’’-treatment period
 - The third term is an interaction term, in effect an indicator for being in the treated group and in the post-treatment period.
 
---
#How Is It Performed?
&lt;br&gt;
**Two-Way Fixed Effects**
&lt;br&gt;

- This third term is equivalent to `\(Treated\)` in the last equation, and `\(\hat{\beta_3}\)` is the difference-in-differences estimate. 
- By standard interaction-term interpretation, `\(\beta_3\)` tells us how much bigger the `\(TreatedGroup\)` effect is in the `\(AfterTreatment\)` than in the before-period.
- Whichever the equation is written, this approach is called the **Two-way fixed effects difference-in-difference estimator** since it has two sets of fixed effects, one for group and one for time period. 
- This model is generally estimated using standard errors that are clustered at the group level.


---
#How Is It Performed?
&lt;br&gt;&lt;br&gt;
**Two-Way Fixed Effects : Advantages**
&lt;br&gt;
&lt;br&gt;
- It is highly intuitive 
- It also allows to apply whatever is know about fixed effects.
- It also allows to account for multi-group designs where there are multiple groups, some of which are treated and some are not, rather than just one treated and untreated group.


---
#How Is It Performed?
&lt;br&gt;&lt;br&gt;
**Two-Way Fixed Effects : Disadvantage**

&lt;br&gt;
&lt;br&gt;

- It does not work very well for **rollout designs,** also known as **staggered treatment timing,** where the treatment is applied at different times to different groups. 



---
#Treatment Effects in Difference-in-Differences
.vcenter[
- Difference-in-differences compares what is seen for the treated group after treatment against the best guess at what the treatment group would have been without treatment.
- The difference between being treated and not being treated for the group that actually gets treated is being isolated. So, an average treatment effect among that group is obtained. In other words it’s the **average treatment on the treated.**
- The estimate that standard difference-in-differences gives is all about how effective the treatment was for the groups that actually got it. 
]
---
#Supporting the Parallel Trends Assumption
- The parallel trends assumption says that, if no treatment had in fact occurred, then the difference in outcomes between the treated and untreated groups would not have changed from before the treatment date to afterwards. 

- It relies directly on a counterfactual observation - **what would have happened without the treatment.**
- There are two tests that can provide some evidence that makes parallel trends look more plausible as an assumption. They are:
 - The **test of prior trends**
 - The **placebo test**

---
#Supporting the Parallel Trends Assumption
&lt;br&gt;
**The test of prior trends looks**
&lt;br&gt;&lt;br&gt;
- The test looks at whether the treated and untreated groups already had differing trends in the leadup to the period where treatment occurred. 
- There are two ways to perform this test:
 - To graph the average outcomes over time in the pre-treatment period and see if they look different.
 - To perform a statistical test to see if the trends are different, and if so, how much different.

---
#Supporting the Parallel Trends Assumption
&lt;br&gt;
**The test of prior trends looks**
&lt;br&gt;&lt;br&gt;
- In the second way of performing the test:
 - The simplest form uses the following regression model:
 `$$Y =\alpha_g+\beta_1Time+\beta_2Time\times Group+\epsilon$$`
 - Here `\(\beta_2Time\times Group\)` allows the time trend to be different for each group.
 - A test of `\(\beta_2=0\)` provides information on whether the trends are different.
 - More complex specification can be made by adding polynomial terms or other nonlinearities to the model.

---
#Supporting the Parallel Trends Assumption
&lt;br&gt;
**The Placebo Test**
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
- Placebo tests are good ways of evaluating untestable assumptions in a number of different research designs


---
#Supporting the Parallel Trends Assumption
&lt;br&gt;
**The Placebo Test**
&lt;br&gt;&lt;br&gt;

- For the difference-in-differences placebo test, the following steps can be applied:
 - Use only the data that came before the treatment went into effect.
 - Pick a fake treatment period.
 - Estimate the same difference-in-differences model you were planning to use 
 -If an “effect” for that treatment date is found which should not be , which is an evidence that there is something wrong with the design, which may imply a violation of parallel trends.



---
#Supporting the Parallel Trends Assumption
&lt;br&gt;
**The Placebo Test**
&lt;br&gt;&lt;br&gt;

- Another way to do this if there are multiple untreated groups is to use all of the data, but drop the data from the treated groups. 
- Then:
 - assign different untreated groups to be fake treated groups, and estimate the DID effect for them. 
 
- This approach is less common since it does not address parallel trends directly but this is a very common placebo test for the synthetic control method.

---
#Long-Term Effects
&lt;br&gt;&lt;br&gt;
- Difference-in-differences can be modified to allow the effect to differ in each time period. In other words, there is a possibility to have **Dynamic treatment effects.**

- A common way of doing this is to first generate a **centered time variable,** which is just the original time variable minus the treatment period.
 - Time in the last period before treatment is `\(t=0\)` the first period with treatment implemented is `\(t=1\)` the second-to-last period before treatment is `\(t=-1\)` and so on.


---
#Long-Term Effects
&lt;br&gt;&lt;br&gt;
- Then, interact the `\(Treatment\)` variable with a set of binary indicator variables for each of the time periods.
`$$Y_k=\alpha_g+\alpha_t+\beta_{-T_1}Treated+\beta_{-(T_1-1)}Treated+...+\beta_1Treated+...+\beta_{T_2}treated+\epsilon$$`
 - Where there are `\(T-1\)` periods before the treatment period, and `\(T_2\)` periods afterwards.
 
---
#Long-Term Effects
&lt;br&gt;&lt;br&gt;
**Advantages of using the setup**

&lt;br&gt;
- There should be no effects among the before-treatment coefficients `\(\beta_{T_1},\beta_{-(T_1-1)},...,\beta_{-1}\)`
- The after-treatment coefficients  `\(\beta_1,...,\beta_{T_2}\)` show the difference-in-difference estimated effect in the relevant period: the effect one period after treatment is `\(\beta_1\)` and so on.
- This approach is easy to implement.

---
#Long-Term Effects
&lt;br&gt;&lt;br&gt;
**Notes for Dynamic Difference-in-differences approach.**

&lt;br&gt;
- Regular difference-in-differences takes advantage of all the data in the entire “after” period to estimate the effect.
 - Each period’s effect estimate in the dynamic treatment effects approach relies mostly on data from that one period. This leads to a shortage of Data and hence less presision in estimate.
 
 
 
---
#Long-Term Effects
&lt;br&gt;&lt;br&gt;
**Notes for Dynamic Difference-in-differences approach.**

&lt;br&gt;&lt;br&gt;
- When interpreting the results, everything is relative to that omitted time-0 effect. As always when there is a categorical variable, everything is relative to the omitted group.
 - There should be no actual effect in period 0. But if there was, it will make the results wrong.


---
#Long-Term Effects
&lt;br&gt;&lt;br&gt;
**Notes for Dynamic Difference-in-differences approach.**

&lt;br&gt;&lt;br&gt;
-  a good way to present the results from a dynamic estimate like this is usually graphically, with time across the `\(x-axis\)` 
and with the difference-in-difference estimates and (usually) a confidence interval on the `\(y-axis\)`


---
#Rollout Designs and Multiple Treatment Periods
.vcenter[
.blockquote[
###Definition: Rollout Design
 A rollout design is when the groups get treated at different times.

]]

---
#Rollout Designs and Multiple Treatment Periods
.vcenter[
.blockquote[
###Example: High Speed Internet on new businesses
- We are interested in the impact of having access to high-speed Internet on the formation of new businesses.
- Prior knowledge: King County got broadband in 2001, Pierce County got it in 2002, and Snohomish County got it in 2003. 
- They each have a before and after period, but those treatment times are not all the same.
]]


---
#Rollout Designs and Multiple Treatment Periods
&lt;br&gt;
**Problem with Rollout Design**

&lt;br&gt;
- From a statistical perspective, when tossing a bunch of valid difference-in-difference designs together, it makes the two-way fixed effects regression not work any more.
- It can even lead to a negative difference-in-differences estimate even if the true effect is positive for everyone in the sample. 
- The two-way fixed effect does not work because this setup leads already-treated groups to get used as an untreated group. 
---
#Doing Multiple Treatment Periods Right
**Problem :**
- When it comes to ways of handling multiple treatment periods in difference-in-differences, where some groups are treated at different times than others (rollout designs), it becomes an “active area of research.”

&lt;br&gt;
**Solution :**
- There are two ways of addressing this problem:
 - Approach to dynamic treatment effects that can fix the staggered rollout problem. 
 -  The method described in Callaway and Sant’Anna (2020).

---
#Doing Multiple Treatment Periods Right
&lt;br&gt;
**Approach to dynamic treatment effects **
&lt;br&gt;
- Models for dynamic treatment effects, modified for use with staggered rollout, can help in the case of staggered difference-in-differences in a few ways:
 - First, they separate out the time periods when the effects take place. 
 - Second, they play a good idea when it comes to difference-in-differences with multiple time periods.
 - Third, because they allow to see how the treatment effect evolves, and because treatment effects evolving is one of the problems with two-way fixed effects, that gives  another opportunity to separate things out and fix them.


---
#Doing Multiple Treatment Periods Right
&lt;br&gt;
**Approach to dynamic treatment effects **
&lt;br&gt;
- They dealt with the treated groups separately
- They compared `\(Y\)` between each treatment group and the untreated group, and use propensity score matching to improve their estimate. 
- So each group-time treatment effect is based on comparing the post-treatment outcomes of the groups treated in that period against the never-treated groups that are most similar to those treated groups.


---
#Picking an Untreated Group with Matching
.vcenter[
- Difference-in-differences only works if the comparison group is good. 
- It needs parallel trends to hold. 
- Since parallel trends cannot be checked directly, an untreated group needs to be picked (or a set of untreated groups) good enough that the assumption is as plausible as it can be.
- When having potential untreated groups, one can choose between them (or aggregate them together) by matching untreated and treated groups, (like, Callaway and Sant’Anna.)
]
---
#Picking an Untreated Group with Matching
- The idea is:
 - Pick a set of predictor variables `\(X\)` from the pre-treatment period, and then use one of the matching methods from Chapter Matching to match each treated group with an untreated group, or produce a set of weights for the untreated groups based on how similar they are to the treated groups.
 - Then, run the difference-in-difference model as normal, with the matching groups/weights applied.


---
#Picking an Untreated Group with Matching
.vcenter[
.blockquote[
###Definition: Synthetic Control 
 In synthetic control, one match the treated group to a bunch of untreated groups based not just on prior covariates but also prior outcomes. 

]]


---
#Picking an Untreated Group with Matching
.vcenter[
- Synthetic control method can also be used in this case.
 - If the synthetic control matching goes well, then prior trends are forced to be the same because weights have been specifically chosen for the untreated groups that have the same average outcomes as your treated group in each prior period.
 ]
 
---
#Picking an Untreated Group with Matching
&lt;br&gt;
**Advantages :Combined matching/difference-in-differences approach**
- Since DID has group fixed effects, it already controls for any differences between treated and untreated groups that is constant over time.
-  If there is some back door between **becomes a treated group** and **evolution of the outcome in the post-treatment period,** as it seems likely there would be, then they are still not identified.
 - If a set of matching variables `\(X\)` is picked, that close the back doors between **which groups become treated and when** and the outcome, thus getting parallel trends back.

---
#Picking an Untreated Group with Matching
&lt;br&gt;
**Problem: Regression to the mean**
- Regression to the mean is a common problem whenever the data varies over time. 
- The basic idea is:
 - if a variable is far above its typical average of this period, then it’s likely to go down next period, i.e., regress back towards the mean.
 - This is because a far-above-average observation is, well, far above average.
- The problem arises if the pre-period outcome levels are related to the probability of treatment. 

---
#Picking an Untreated Group with Matching
&lt;br&gt;
**Problem: Regression to the mean**

&lt;br&gt;
.blockquote[
###Example: Effect of policy on unemployment 
- There are two cities with similar covariates. 
- Policymakers are planning to put a job training program in place and want to know the effects of the program on unemployment. 
- They choose City A for the program since unemployment is currently bad in City A. 
- Therefore, A is considered as the treated group and B as the untreated group, since B has similar covariates.
]

---
#Picking an Untreated Group with Matching
&lt;br&gt;
**Problem: Regression to the mean**

&lt;br&gt;
.blockquote[
###Example: Effect of policy on unemployment 
- After the policy goes into effect, unemployment might get    better in City A for two reasons:
 - The effect of the policy
 - Regression to the mean
- If A was just having an unusually bad period when policymakers were choosing where to put the training program. 
- Difference-in-differences cannot tell the two apart, so the estimate is wrong

]


---
#Picking an Untreated Group with Matching
&lt;br&gt;
**Problem: Regression to the mean**

&lt;br&gt;
.blockquote[
###Example: Effect of policy on unemployment 
- This is only a problem because A and B are matched.
- If a bunch of untreated cities were used, or a random city from a set of potential comparisons, the bias would not be there.
- That is because B was selected as a good match for an unusually bad time in A’s history. 
- The matching emphasizes comparisons that are especially subject to regression to the mean.
]


---
#The Unfurling Logic of Difference-in-Differences
Let's say, We want to see how a difference in a relationship changes from before to after. 

&lt;br&gt;
.blockquote[
###Example: Training program on educational income disparities
- Let’s consider a teacher training program that is introduced in some districts but not others.
- The goal of this training program is to help ease educational income disparities. 
- The relationship between parental income and student test scores should be weaker with the introduction of the training program.
- It is already known: the effect of `\(Income\)` on `\(TestScore\)`
`$$TestScore=\beta_0+\beta_1Income+\epsilon$$`
]



---
#The Unfurling Logic of Difference-in-Differences

&lt;br&gt;
.blockquote[
###Example: Training program on educational income disparities
- Interest is to perform difference-in-differences on `\(\beta_1\)` instead of `\(Y\)`
`$$(\beta_1^{Treated,After}-\beta_1^{Treated,Before})-(\beta_1^{Untreated,After}-\beta_1^{Unreated,Before})$$`
- In order to know the "within"  variation in the effect:
`$$TestScore = \beta_0+\beta_1Income+\beta_2After+\beta_3Income\cdot After+\epsilon$$`
- Estimate that model for the treated group, and  `\(\beta_3\)` gives us:
`$$\beta_1^{Treated,After}-\beta_1^{Treated,Before}$$`
]

---


#The Unfurling Logic of Difference-in-Differences

&lt;br&gt;
.blockquote[
###Example: Training program on educational income disparities
- Estimate it for the untreated group:
`$$\beta_1^{Untreated,After}-\beta_1^{Unreated,Before}$$`
- Everything can be combined into one regression with a triple-interaction term:

`\begin{align*}
TestScore = &amp;\beta_0+\beta_1Income+  \beta_2After + \beta_3Income\times After\\
+&amp;\beta_4 Treated+\beta_5Treated\times Income+ \beta_6Treated\times After\\ 
+&amp;\beta_7 Treated \times Income \times After + \epsilon 
\end{align*}`

- This is difference-in-differences but on a relationship rather than the average of an outcome.
]

---
#The Unfurling Logic of Difference-in-Differences
&lt;br&gt;
**Application**

&lt;br&gt;
- Aside from applying DID to effects themselves (relationships),  difference-in-differences logic can also be applied to other kinds of summary descriptions of a single variable rather than the mean (like DID would do).
 - One application of this is in using DID with quantile regression: a form of regression that looks at how predictors affect the entire distribution of a variable. 

- DID can also be applied to difference-in-differences itself and get the difference-in-difference-in-differences model, also known as triple-differences or DIDID
---
#The Unfurling Logic of Difference-in-Differences
&lt;br&gt;
**Application**

&lt;br&gt;&lt;br&gt;
- DIDID could be used to see how a newly implemented policy changes a DID-estimated effect. 
 - However, DIDID is also used to help strengthen the parallel trends assumption by finding a treated group that shouldn’t be affected at all, and subtracting out their effect. 

---

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="remark-zoom.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": true
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
